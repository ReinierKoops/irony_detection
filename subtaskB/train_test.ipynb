{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"loads the data, pre-trainied embeddings, feature sets, and trains a voting classifier for task B and subsequently \n",
    "   tests the model on the held-out test data\"\"\"\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import logging\n",
    "import codecs\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from random import randint\n",
    "import gensim.models\n",
    "import word2vecReaderUtils as utils\n",
    "from word2vecReader import *\n",
    "import json\n",
    "\n",
    "from load import parse_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramFeaturize(corpus):\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True).tokenize\n",
    "    #vectorizer = TfidfVectorizer(strip_accents=\"unicode\", analyzer=\"word\", tokenizer=tokenizer, stop_words=\"english\")\n",
    "    bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),tokenizer=tokenizer, min_df=1) #token_pattern=r'\\b\\w+\\b',\n",
    "    analyze = bigram_vectorizer.build_analyzer()\n",
    "\n",
    "    X = bigram_vectorizer.fit_transform(corpus).toarray()\n",
    "    strUnits = bigram_vectorizer.get_feature_names()\n",
    "    print(\"len features\",len(bigram_vectorizer.get_feature_names()))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "  def wvVectors(corpus):\n",
    "    tweetVectors = []\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True).tokenize\n",
    "    wvModel = Word2Vec.load_word2vec_format('../install_dependencies/word2vec_twitter_model.bin', binary=True)\n",
    "#     wvModel = Word2Vec.load_word2vec_format('/Users/shiva/Downloads/word2vec_twitter_model/word2vec_twitter_model.bin', binary=True)\n",
    "    emojiModel = gensim.models.KeyedVectors.load_word2vec_format('../../Task3/extra_resources/emoji2vec.bin', binary=True)\n",
    "    unknowns = []\n",
    "    for tweet in corpus:\n",
    "        t = tokenizer(tweet)\n",
    "        sentVectors = []\n",
    "        for word in t:\n",
    "            if word in wvModel:\n",
    "                sentVectors.append(wvModel[word])\n",
    "            elif word in emojiModel:\n",
    "                sentVectors.append(np.concatenate((emojiModel[word], np.zeros(100))))\n",
    "        if len(sentVectors)==0:\n",
    "            print(\"empty sentence\",t)\n",
    "        tweetVectors.append(sentVectors)\n",
    "    return tweetVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def wvConcatVectorsFeaturize(corpus):\n",
    "    concatenatedVectors = []\n",
    "    tVectors = wvVectors(corpus)\n",
    "#     maxlength_w = max([len(t) for t in tVectors])\n",
    "    maxlength_w = 41 # based on both train and test \n",
    "    for vecs in tVectors:\n",
    "        concatVec = []\n",
    "        for i in range(maxlength_w):\n",
    "            if i<len(vecs):\n",
    "                concatVec = np.concatenate((concatVec,vecs[i]))\n",
    "            else:\n",
    "                concatVec = np.concatenate((concatVec,np.zeros(400)))\n",
    "        concatenatedVectors.append(concatVec)\n",
    "    return concatenatedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len features 60360\n",
      "empty sentence ['illridewithyou']\n",
      "empty sentence []\n",
      "X dimension 76847\n",
      "class counts: [[0, 1923], [1, 1390], [2, 316], [3, 205]]\n"
     ]
    }
   ],
   "source": [
    "# Experiment settings\n",
    "\n",
    "DATASET_FP = \"../datasets/train/SemEval2018-T3-train-taskB_emoji.txt\"\n",
    "TASK = \"B\" # Define, A or B\n",
    "FNAME = './predictions-task' + TASK + '.txt'\n",
    "PREDICTIONSFILE = open(FNAME, \"w\")\n",
    "EXTRA_FEATURES = 1\n",
    "\n",
    "# Loading dataset and featurised simple Tfidf-BoW model\n",
    "corpus, y = parse_dataset(DATASET_FP)\n",
    "\n",
    "test_corpus, test_y = parse_dataset('../datasets/goldtest_TaskB/SemEval2018-T3_gold_test_taskB_emoji.txt')\n",
    "\n",
    "X_bigram = ngramFeaturize(corpus+test_corpus)\n",
    "\n",
    "X = wvConcatVectorsFeaturize(corpus)\n",
    "\n",
    "X = list(X)\n",
    "y = np.array(y)\n",
    "#print(\"shape X after concatenation:\", X.shape)\n",
    "\n",
    "if EXTRA_FEATURES:\n",
    "    extraFeatures = np.load(open('./all_train_feats_TaskB.npy', 'rb'))\n",
    "    for i in range(len(X)):\n",
    "        X[i] = np.concatenate((X[i],X_bigram[i],extraFeatures[i]))\n",
    "print(\"X dimension\",len(X[0]))\n",
    "X = np.array(X)\n",
    "\n",
    "class_counts = np.asarray(np.unique(y, return_counts=True)).T.tolist()\n",
    "print (\"class counts:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "K_FOLDS = 10 # 10-fold crossvalidation\n",
    "\n",
    "clf1 = LogisticRegression(multi_class = 'ovr', solver = 'liblinear', class_weight = {0:1, 1:1, 2:3,3:3})\n",
    "clf2 = LogisticRegression(multi_class = 'ovr', solver = 'liblinear', class_weight = {0:1, 1:1, 2:1, 3:1})\n",
    "clf3 = LogisticRegression(multi_class = 'ovr', solver = 'liblinear', class_weight = {0:1, 1:1, 2:2, 3:2})\n",
    "\n",
    "CLF = VotingClassifier(estimators=[('lr1', clf1), ('lr2', clf2), ('lr3', clf3)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score Task B [ 0.70644391  0.65843331  0.27684964  0.04444444]\n",
      "F1-score Task B 0.421542827585\n"
     ]
    }
   ],
   "source": [
    "# Returns an array of the same size as 'y' where each entry is a prediction obtained by cross validated\n",
    "predicted = cross_val_predict(CLF, X, y, cv=K_FOLDS)\n",
    "\n",
    "# Modify F1-score calculation depending on the task\n",
    "if TASK.lower() == 'a':\n",
    "    score = metrics.f1_score(y, predicted, pos_label=1)\n",
    "elif TASK.lower() == 'b':\n",
    "     # if you set average to None, it will return results for each class separately \n",
    "    score = metrics.f1_score(y, predicted, average=None)\n",
    "    score_ = metrics.f1_score(y, predicted, average='macro') \n",
    "print (\"F1-score Task\", TASK, score)\n",
    "print (\"F1-score Task\", TASK, score_)\n",
    "for p in predicted:\n",
    "    PREDICTIONSFILE.write(\"{}\\n\".format(p))\n",
    "PREDICTIONSFILE.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test dimension 76847\n",
      "Fit on the whole Train ...\n",
      "Ready to TEST\n",
      "F1-score Task B [ 0.78991597  0.56493506  0.31404959  0.        ]\n",
      "F1-score Task B 0.417225154525\n"
     ]
    }
   ],
   "source": [
    "X_bigram_vec_test = X_bigram[len(corpus):] \n",
    "X_test = wvConcatVectorsFeaturize(test_corpus)\n",
    "\n",
    "X_test = list(X_test)\n",
    "#print(\"shape X after concatination:\", X.shape)\n",
    "\n",
    "if EXTRA_FEATURES:\n",
    "    extraFeatures = np.load(\"./all_test_feats_TaskB.npy\")\n",
    "    for i in range(len(X_test)):\n",
    "        X_test[i] = np.concatenate((X_test[i],X_bigram_vec_test[i], extraFeatures[i]))\n",
    "print(\"X_test dimension\",len(X_test[0]))\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "print(\"Fit on the whole Train ...\")\n",
    "CLF.fit(X, y)\n",
    "\n",
    "print(\"Ready to TEST\")\n",
    "\n",
    "\n",
    "y_test_predicted = CLF.predict(X_test)\n",
    "\n",
    "with open('test_prediction_TaskB_shiva.txt', 'w') as f:\n",
    "    for y in y_test_predicted:\n",
    "        f.write(str(y)+\"\\n\")\n",
    "        \n",
    "score = metrics.f1_score(test_y, y_test_predicted, average=None)\n",
    "score_ = metrics.f1_score(test_y, y_test_predicted, average='macro') \n",
    "print (\"F1-score Task\", TASK, score)\n",
    "print (\"F1-score Task\", TASK, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
