{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sentiment                                               text\n",
      "9249   __label__positive  can we get him to beat out the wanted atleast ...\n",
      "4673    __label__neutral  My heart felt condolences go out to the Giffor...\n",
      "6914    __label__neutral  =@bgregory857 You may not know this but Americ...\n",
      "10382  __label__positive  I found out i was gay in the 4th grade...well ...\n",
      "15004   __label__neutral  WWE Monday Night RAW results - http://t.co/Tnn...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_names = ['tweethash','sentiment','text']\n",
    "data_path = 'SemEval2017-sentiment_english.csv'\n",
    "\n",
    "tweet_data = pd.read_csv(data_path, header=None, names=col_names, encoding=\"ISO-8859-1\").sample(frac=1) # .sample(frac=1) shuffles the data\n",
    "tweet_data = tweet_data[['sentiment', 'text']] # Disregard other columns\n",
    "print(tweet_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "allowed_chars = ' AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz0123456789~`!@#$%^&*()-=_+[]{}|;:\",./<>?'\n",
    "punct = '!?,.@#'\n",
    "maxlen = 280\n",
    "\n",
    "def preprocess(text):\n",
    "    return ''.join([' ' + char + ' ' if char in punct else char for char in [char for char in re.sub(r'http\\S+', 'http', text, flags=re.MULTILINE) if char in allowed_chars]])[:maxlen]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data['text'] = tweet_data['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_data['sentiment'] = '__label__' + tweet_data['sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directory for saving data if it does not already exist\n",
    "data_dir = './processed-data'\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "# Save a percentage of the data (you could also only load a fraction of the data instead)\n",
    "amount = 0.125\n",
    "\n",
    "tweet_data.iloc[0:int(len(tweet_data)*0.8*amount)].to_csv(data_dir + '/train.csv', sep='\\t', index=False, header=False)\n",
    "tweet_data.iloc[int(len(tweet_data)*0.8*amount):int(len(tweet_data)*0.9*amount)].to_csv(data_dir + '/test.csv', sep='\\t', index=False, header=False)\n",
    "tweet_data.iloc[int(len(tweet_data)*0.9*amount):int(len(tweet_data)*1.0*amount)].to_csv(data_dir + '/dev.csv', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-09 23:17:32,837 Reading data from processed-data\n",
      "2020-03-09 23:17:32,838 Train: processed-data/train.csv\n",
      "2020-03-09 23:17:32,838 Dev: processed-data/dev.csv\n",
      "2020-03-09 23:17:32,839 Test: processed-data/test.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from pathlib import Path\n",
    "\n",
    "#corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_dir), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "\n",
    "\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: Corpus = ClassificationCorpus(Path(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-09 23:17:33,946 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000/160000 [00:30<00:00, 5191.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-09 23:18:04,819 [b'4', b'0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings\n",
    "\n",
    "word_embeddings = [WordEmbeddings('glove'), \n",
    "                   #FlairEmbeddings('news-forward'), \n",
    "                   #FlairEmbeddings('news-backward')\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import DocumentRNNEmbeddings\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-09 23:18:05,877 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:18:05,879 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-03-09 23:18:05,880 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:18:05,881 Corpus: \"Corpus: 160000 train + 20000 dev + 20000 test sentences\"\n",
      "2020-03-09 23:18:05,882 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:18:05,883 Parameters:\n",
      "2020-03-09 23:18:05,883  - learning_rate: \"0.1\"\n",
      "2020-03-09 23:18:05,884  - mini_batch_size: \"32\"\n",
      "2020-03-09 23:18:05,885  - patience: \"8\"\n",
      "2020-03-09 23:18:05,886  - anneal_factor: \"0.5\"\n",
      "2020-03-09 23:18:05,887  - max_epochs: \"200\"\n",
      "2020-03-09 23:18:05,888  - shuffle: \"True\"\n",
      "2020-03-09 23:18:05,888  - train_with_dev: \"False\"\n",
      "2020-03-09 23:18:05,889  - batch_growth_annealing: \"False\"\n",
      "2020-03-09 23:18:05,889 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:18:05,890 Model training base path: \"model-saves\"\n",
      "2020-03-09 23:18:05,891 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:18:05,892 Device: cpu\n",
      "2020-03-09 23:18:05,893 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:18:05,893 Embeddings storage mode: cpu\n",
      "2020-03-09 23:18:05,895 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:19:41,459 epoch 1 - iter 500/5000 - loss 0.68349691 - samples/sec: 174.04\n",
      "2020-03-09 23:21:17,286 epoch 1 - iter 1000/5000 - loss 0.66597951 - samples/sec: 173.30\n",
      "2020-03-09 23:22:53,647 epoch 1 - iter 1500/5000 - loss 0.65671293 - samples/sec: 172.29\n",
      "2020-03-09 23:24:31,020 epoch 1 - iter 2000/5000 - loss 0.65100293 - samples/sec: 170.37\n",
      "2020-03-09 23:26:08,260 epoch 1 - iter 2500/5000 - loss 0.64620377 - samples/sec: 170.68\n",
      "2020-03-09 23:27:45,664 epoch 1 - iter 3000/5000 - loss 0.64189847 - samples/sec: 170.79\n",
      "2020-03-09 23:29:22,796 epoch 1 - iter 3500/5000 - loss 0.63786938 - samples/sec: 170.73\n",
      "2020-03-09 23:31:01,199 epoch 1 - iter 4000/5000 - loss 0.63274947 - samples/sec: 168.37\n",
      "2020-03-09 23:32:39,471 epoch 1 - iter 4500/5000 - loss 0.63001184 - samples/sec: 168.57\n",
      "2020-03-09 23:34:18,372 epoch 1 - iter 5000/5000 - loss 0.62661191 - samples/sec: 168.00\n",
      "2020-03-09 23:34:18,427 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:34:18,428 EPOCH 1 done: loss 0.6266 - lr 0.1000\n",
      "2020-03-09 23:34:37,461 DEV : loss 0.5376811027526855 - score 0.7317\n",
      "2020-03-09 23:34:42,165 BAD EPOCHS (no improvement): 0\n",
      "2020-03-09 23:34:45,195 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:36:22,923 epoch 2 - iter 500/5000 - loss 0.59998037 - samples/sec: 169.59\n",
      "2020-03-09 23:37:59,891 epoch 2 - iter 1000/5000 - loss 0.59643245 - samples/sec: 171.16\n",
      "2020-03-09 23:39:37,042 epoch 2 - iter 1500/5000 - loss 0.59167520 - samples/sec: 170.60\n",
      "2020-03-09 23:41:14,223 epoch 2 - iter 2000/5000 - loss 0.58968771 - samples/sec: 170.58\n",
      "2020-03-09 23:42:51,213 epoch 2 - iter 2500/5000 - loss 0.58918197 - samples/sec: 170.39\n",
      "2020-03-09 23:44:28,405 epoch 2 - iter 3000/5000 - loss 0.58753329 - samples/sec: 170.51\n",
      "2020-03-09 23:46:06,477 epoch 2 - iter 3500/5000 - loss 0.58783106 - samples/sec: 168.51\n",
      "2020-03-09 23:47:44,220 epoch 2 - iter 4000/5000 - loss 0.58675951 - samples/sec: 169.60\n",
      "2020-03-09 23:49:22,024 epoch 2 - iter 4500/5000 - loss 0.58512943 - samples/sec: 169.50\n",
      "2020-03-09 23:50:59,916 epoch 2 - iter 5000/5000 - loss 0.58365981 - samples/sec: 169.28\n",
      "2020-03-09 23:50:59,982 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:50:59,983 EPOCH 2 done: loss 0.5837 - lr 0.1000\n",
      "2020-03-09 23:51:18,874 DEV : loss 0.5238117575645447 - score 0.7446\n",
      "2020-03-09 23:51:23,548 BAD EPOCHS (no improvement): 0\n",
      "2020-03-09 23:51:26,500 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-09 23:53:03,788 epoch 3 - iter 500/5000 - loss 0.57086232 - samples/sec: 170.53\n",
      "2020-03-09 23:54:41,959 epoch 3 - iter 1000/5000 - loss 0.56790782 - samples/sec: 169.08\n",
      "2020-03-09 23:56:19,499 epoch 3 - iter 1500/5000 - loss 0.57039227 - samples/sec: 169.90\n",
      "2020-03-09 23:57:57,223 epoch 3 - iter 2000/5000 - loss 0.57110012 - samples/sec: 169.56\n",
      "2020-03-09 23:59:34,800 epoch 3 - iter 2500/5000 - loss 0.57208334 - samples/sec: 170.28\n",
      "2020-03-10 00:01:11,787 epoch 3 - iter 3000/5000 - loss 0.57105367 - samples/sec: 170.89\n",
      "2020-03-10 00:02:49,512 epoch 3 - iter 3500/5000 - loss 0.56976722 - samples/sec: 169.51\n",
      "2020-03-10 00:04:26,752 epoch 3 - iter 4000/5000 - loss 0.56967921 - samples/sec: 170.39\n",
      "2020-03-10 00:06:04,762 epoch 3 - iter 4500/5000 - loss 0.56894195 - samples/sec: 169.05\n",
      "2020-03-10 00:07:41,384 epoch 3 - iter 5000/5000 - loss 0.56805485 - samples/sec: 171.57\n",
      "2020-03-10 00:07:41,450 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 00:07:41,451 EPOCH 3 done: loss 0.5681 - lr 0.1000\n",
      "2020-03-10 00:08:00,171 DEV : loss 0.5033139586448669 - score 0.7539\n",
      "2020-03-10 00:08:04,864 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 00:08:07,835 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 00:09:45,964 epoch 4 - iter 500/5000 - loss 0.55311733 - samples/sec: 169.39\n",
      "2020-03-10 00:11:23,823 epoch 4 - iter 1000/5000 - loss 0.55564047 - samples/sec: 169.65\n",
      "2020-03-10 00:12:59,899 epoch 4 - iter 1500/5000 - loss 0.55617185 - samples/sec: 172.37\n",
      "2020-03-10 00:14:37,568 epoch 4 - iter 2000/5000 - loss 0.55781559 - samples/sec: 170.06\n",
      "2020-03-10 00:16:15,572 epoch 4 - iter 2500/5000 - loss 0.55810825 - samples/sec: 168.86\n",
      "2020-03-10 00:17:53,012 epoch 4 - iter 3000/5000 - loss 0.55909496 - samples/sec: 170.48\n",
      "2020-03-10 00:19:30,221 epoch 4 - iter 3500/5000 - loss 0.55805506 - samples/sec: 170.26\n",
      "2020-03-10 00:21:07,685 epoch 4 - iter 4000/5000 - loss 0.55768624 - samples/sec: 170.34\n",
      "2020-03-10 00:22:45,314 epoch 4 - iter 4500/5000 - loss 0.55618884 - samples/sec: 169.64\n",
      "2020-03-10 00:24:22,913 epoch 4 - iter 5000/5000 - loss 0.55649225 - samples/sec: 169.60\n",
      "2020-03-10 00:24:22,980 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 00:24:22,981 EPOCH 4 done: loss 0.5565 - lr 0.1000\n",
      "2020-03-10 00:24:43,984 DEV : loss 0.49253028631210327 - score 0.7652\n",
      "2020-03-10 00:24:48,915 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 00:24:51,903 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 00:26:28,075 epoch 5 - iter 500/5000 - loss 0.54648606 - samples/sec: 172.47\n",
      "2020-03-10 00:28:05,844 epoch 5 - iter 1000/5000 - loss 0.54864470 - samples/sec: 169.34\n",
      "2020-03-10 00:29:42,689 epoch 5 - iter 1500/5000 - loss 0.55040357 - samples/sec: 171.03\n",
      "2020-03-10 00:31:20,364 epoch 5 - iter 2000/5000 - loss 0.54954587 - samples/sec: 169.55\n",
      "2020-03-10 00:32:58,497 epoch 5 - iter 2500/5000 - loss 0.54931338 - samples/sec: 169.29\n",
      "2020-03-10 00:34:36,317 epoch 5 - iter 3000/5000 - loss 0.54878093 - samples/sec: 169.27\n",
      "2020-03-10 00:36:13,499 epoch 5 - iter 3500/5000 - loss 0.54914765 - samples/sec: 170.48\n",
      "2020-03-10 00:37:51,444 epoch 5 - iter 4000/5000 - loss 0.54951365 - samples/sec: 169.04\n",
      "2020-03-10 00:39:30,434 epoch 5 - iter 4500/5000 - loss 0.54994233 - samples/sec: 167.86\n",
      "2020-03-10 00:41:08,669 epoch 5 - iter 5000/5000 - loss 0.54926494 - samples/sec: 168.55\n",
      "2020-03-10 00:41:08,735 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 00:41:08,736 EPOCH 5 done: loss 0.5493 - lr 0.1000\n",
      "2020-03-10 00:41:27,295 DEV : loss 0.49043095111846924 - score 0.7648\n",
      "2020-03-10 00:41:31,968 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 00:41:31,970 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 00:43:08,747 epoch 6 - iter 500/5000 - loss 0.54641009 - samples/sec: 171.43\n",
      "2020-03-10 00:44:46,025 epoch 6 - iter 1000/5000 - loss 0.54753842 - samples/sec: 170.34\n",
      "2020-03-10 00:46:23,737 epoch 6 - iter 1500/5000 - loss 0.54690477 - samples/sec: 169.62\n",
      "2020-03-10 00:48:01,755 epoch 6 - iter 2000/5000 - loss 0.54626034 - samples/sec: 169.00\n",
      "2020-03-10 00:49:39,161 epoch 6 - iter 2500/5000 - loss 0.54472713 - samples/sec: 170.07\n",
      "2020-03-10 00:51:17,329 epoch 6 - iter 3000/5000 - loss 0.54455505 - samples/sec: 168.72\n",
      "2020-03-10 00:52:55,093 epoch 6 - iter 3500/5000 - loss 0.54491724 - samples/sec: 169.46\n",
      "2020-03-10 00:54:33,276 epoch 6 - iter 4000/5000 - loss 0.54471543 - samples/sec: 169.27\n",
      "2020-03-10 00:56:11,765 epoch 6 - iter 4500/5000 - loss 0.54493247 - samples/sec: 168.19\n",
      "2020-03-10 00:57:49,632 epoch 6 - iter 5000/5000 - loss 0.54374427 - samples/sec: 169.35\n",
      "2020-03-10 00:57:49,696 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 00:57:49,697 EPOCH 6 done: loss 0.5437 - lr 0.1000\n",
      "2020-03-10 00:58:08,643 DEV : loss 0.4780201315879822 - score 0.7749\n",
      "2020-03-10 00:58:13,358 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 00:58:16,344 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 00:59:53,956 epoch 7 - iter 500/5000 - loss 0.53624043 - samples/sec: 170.04\n",
      "2020-03-10 01:01:30,631 epoch 7 - iter 1000/5000 - loss 0.53891406 - samples/sec: 170.98\n",
      "2020-03-10 01:03:08,589 epoch 7 - iter 1500/5000 - loss 0.54073934 - samples/sec: 169.22\n",
      "2020-03-10 01:04:45,786 epoch 7 - iter 2000/5000 - loss 0.54077684 - samples/sec: 170.36\n",
      "2020-03-10 01:06:23,455 epoch 7 - iter 2500/5000 - loss 0.54003687 - samples/sec: 170.01\n",
      "2020-03-10 01:08:00,997 epoch 7 - iter 3000/5000 - loss 0.54082574 - samples/sec: 169.72\n",
      "2020-03-10 01:09:38,626 epoch 7 - iter 3500/5000 - loss 0.54044548 - samples/sec: 169.52\n",
      "2020-03-10 01:11:15,895 epoch 7 - iter 4000/5000 - loss 0.54033719 - samples/sec: 170.30\n",
      "2020-03-10 01:12:52,996 epoch 7 - iter 4500/5000 - loss 0.53978728 - samples/sec: 170.58\n",
      "2020-03-10 01:14:31,039 epoch 7 - iter 5000/5000 - loss 0.53972710 - samples/sec: 168.83\n",
      "2020-03-10 01:14:31,106 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 01:14:31,107 EPOCH 7 done: loss 0.5397 - lr 0.1000\n",
      "2020-03-10 01:14:51,472 DEV : loss 0.4736984372138977 - score 0.777\n",
      "2020-03-10 01:14:56,077 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 01:14:59,056 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 01:16:36,337 epoch 8 - iter 500/5000 - loss 0.53707582 - samples/sec: 170.56\n",
      "2020-03-10 01:18:14,640 epoch 8 - iter 1000/5000 - loss 0.53486708 - samples/sec: 169.02\n",
      "2020-03-10 01:19:52,834 epoch 8 - iter 1500/5000 - loss 0.53517910 - samples/sec: 168.65\n",
      "2020-03-10 01:21:30,828 epoch 8 - iter 2000/5000 - loss 0.53409330 - samples/sec: 169.61\n",
      "2020-03-10 01:23:08,316 epoch 8 - iter 2500/5000 - loss 0.53458205 - samples/sec: 170.00\n",
      "2020-03-10 01:24:45,566 epoch 8 - iter 3000/5000 - loss 0.53436282 - samples/sec: 170.39\n",
      "2020-03-10 01:26:23,227 epoch 8 - iter 3500/5000 - loss 0.53453975 - samples/sec: 170.20\n",
      "2020-03-10 01:28:01,383 epoch 8 - iter 4000/5000 - loss 0.53443976 - samples/sec: 168.69\n",
      "2020-03-10 01:29:39,029 epoch 8 - iter 4500/5000 - loss 0.53514763 - samples/sec: 170.19\n",
      "2020-03-10 01:31:16,484 epoch 8 - iter 5000/5000 - loss 0.53432650 - samples/sec: 169.99\n",
      "2020-03-10 01:31:16,550 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 01:31:16,551 EPOCH 8 done: loss 0.5343 - lr 0.1000\n",
      "2020-03-10 01:31:35,412 DEV : loss 0.4702403247356415 - score 0.7739\n",
      "2020-03-10 01:31:40,101 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 01:31:40,102 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 01:33:18,840 epoch 9 - iter 500/5000 - loss 0.52665516 - samples/sec: 169.08\n",
      "2020-03-10 01:34:55,814 epoch 9 - iter 1000/5000 - loss 0.52910356 - samples/sec: 170.76\n",
      "2020-03-10 01:36:33,301 epoch 9 - iter 1500/5000 - loss 0.52784022 - samples/sec: 169.85\n",
      "2020-03-10 01:38:11,099 epoch 9 - iter 2000/5000 - loss 0.52957063 - samples/sec: 169.85\n",
      "2020-03-10 01:39:48,058 epoch 9 - iter 2500/5000 - loss 0.53144279 - samples/sec: 170.76\n",
      "2020-03-10 01:41:25,723 epoch 9 - iter 3000/5000 - loss 0.53124383 - samples/sec: 169.46\n",
      "2020-03-10 01:43:03,255 epoch 9 - iter 3500/5000 - loss 0.53190433 - samples/sec: 169.74\n",
      "2020-03-10 01:44:40,993 epoch 9 - iter 4000/5000 - loss 0.53211855 - samples/sec: 169.43\n",
      "2020-03-10 01:46:19,498 epoch 9 - iter 4500/5000 - loss 0.53154326 - samples/sec: 168.80\n",
      "2020-03-10 01:47:56,959 epoch 9 - iter 5000/5000 - loss 0.53142849 - samples/sec: 169.99\n",
      "2020-03-10 01:47:57,025 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 01:47:57,026 EPOCH 9 done: loss 0.5314 - lr 0.1000\n",
      "2020-03-10 01:48:16,123 DEV : loss 0.4688743054866791 - score 0.7775\n",
      "2020-03-10 01:48:20,772 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 01:48:23,746 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 01:50:00,883 epoch 10 - iter 500/5000 - loss 0.53077803 - samples/sec: 171.14\n",
      "2020-03-10 01:51:39,197 epoch 10 - iter 1000/5000 - loss 0.52728145 - samples/sec: 168.83\n",
      "2020-03-10 01:53:17,136 epoch 10 - iter 1500/5000 - loss 0.52754850 - samples/sec: 168.88\n",
      "2020-03-10 01:54:55,108 epoch 10 - iter 2000/5000 - loss 0.52819503 - samples/sec: 169.35\n",
      "2020-03-10 01:56:31,972 epoch 10 - iter 2500/5000 - loss 0.52777094 - samples/sec: 171.42\n",
      "2020-03-10 01:58:09,770 epoch 10 - iter 3000/5000 - loss 0.52784776 - samples/sec: 170.00\n",
      "2020-03-10 01:59:47,373 epoch 10 - iter 3500/5000 - loss 0.52907203 - samples/sec: 170.10\n",
      "2020-03-10 02:01:25,742 epoch 10 - iter 4000/5000 - loss 0.52956955 - samples/sec: 168.64\n",
      "2020-03-10 02:03:03,307 epoch 10 - iter 4500/5000 - loss 0.52929730 - samples/sec: 170.14\n",
      "2020-03-10 02:04:41,482 epoch 10 - iter 5000/5000 - loss 0.52891261 - samples/sec: 168.97\n",
      "2020-03-10 02:04:41,547 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 02:04:41,548 EPOCH 10 done: loss 0.5289 - lr 0.1000\n",
      "2020-03-10 02:05:00,252 DEV : loss 0.4651927649974823 - score 0.7819\n",
      "2020-03-10 02:05:05,024 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 02:05:08,060 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 02:06:45,231 epoch 11 - iter 500/5000 - loss 0.52429623 - samples/sec: 170.90\n",
      "2020-03-10 02:08:22,486 epoch 11 - iter 1000/5000 - loss 0.52345980 - samples/sec: 169.93\n",
      "2020-03-10 02:09:59,365 epoch 11 - iter 1500/5000 - loss 0.52321074 - samples/sec: 171.16\n",
      "2020-03-10 02:11:37,952 epoch 11 - iter 2000/5000 - loss 0.52399220 - samples/sec: 167.56\n",
      "2020-03-10 02:13:16,265 epoch 11 - iter 2500/5000 - loss 0.52454473 - samples/sec: 168.57\n",
      "2020-03-10 02:14:53,782 epoch 11 - iter 3000/5000 - loss 0.52480578 - samples/sec: 169.93\n",
      "2020-03-10 02:16:31,798 epoch 11 - iter 3500/5000 - loss 0.52451313 - samples/sec: 169.15\n",
      "2020-03-10 02:18:10,360 epoch 11 - iter 4000/5000 - loss 0.52534298 - samples/sec: 167.53\n",
      "2020-03-10 02:19:48,819 epoch 11 - iter 4500/5000 - loss 0.52580047 - samples/sec: 168.28\n",
      "2020-03-10 02:21:27,491 epoch 11 - iter 5000/5000 - loss 0.52552833 - samples/sec: 167.89\n",
      "2020-03-10 02:21:27,561 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 02:21:27,562 EPOCH 11 done: loss 0.5255 - lr 0.1000\n",
      "2020-03-10 02:21:46,543 DEV : loss 0.46401992440223694 - score 0.7798\n",
      "2020-03-10 02:21:51,243 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 02:21:51,245 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 02:23:28,755 epoch 12 - iter 500/5000 - loss 0.51855457 - samples/sec: 170.15\n",
      "2020-03-10 02:25:07,622 epoch 12 - iter 1000/5000 - loss 0.51887450 - samples/sec: 167.59\n",
      "2020-03-10 02:26:44,598 epoch 12 - iter 1500/5000 - loss 0.52022352 - samples/sec: 170.89\n",
      "2020-03-10 02:28:23,856 epoch 12 - iter 2000/5000 - loss 0.52112183 - samples/sec: 166.83\n",
      "2020-03-10 02:30:00,700 epoch 12 - iter 2500/5000 - loss 0.52128244 - samples/sec: 171.21\n",
      "2020-03-10 02:31:37,699 epoch 12 - iter 3000/5000 - loss 0.52126357 - samples/sec: 170.88\n",
      "2020-03-10 02:33:17,117 epoch 12 - iter 3500/5000 - loss 0.52203451 - samples/sec: 166.59\n",
      "2020-03-10 02:34:55,176 epoch 12 - iter 4000/5000 - loss 0.52348674 - samples/sec: 168.98\n",
      "2020-03-10 02:36:33,221 epoch 12 - iter 4500/5000 - loss 0.52335500 - samples/sec: 168.96\n",
      "2020-03-10 02:38:10,611 epoch 12 - iter 5000/5000 - loss 0.52349420 - samples/sec: 170.16\n",
      "2020-03-10 02:38:10,676 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 02:38:10,677 EPOCH 12 done: loss 0.5235 - lr 0.1000\n",
      "2020-03-10 02:38:29,608 DEV : loss 0.4588448107242584 - score 0.7847\n",
      "2020-03-10 02:38:34,333 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 02:38:37,284 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 02:40:16,173 epoch 13 - iter 500/5000 - loss 0.51467033 - samples/sec: 168.68\n",
      "2020-03-10 02:41:53,718 epoch 13 - iter 1000/5000 - loss 0.51885602 - samples/sec: 169.80\n",
      "2020-03-10 02:43:31,276 epoch 13 - iter 1500/5000 - loss 0.52166438 - samples/sec: 169.73\n",
      "2020-03-10 02:45:08,743 epoch 13 - iter 2000/5000 - loss 0.51990247 - samples/sec: 169.98\n",
      "2020-03-10 02:46:46,394 epoch 13 - iter 2500/5000 - loss 0.52070466 - samples/sec: 169.65\n",
      "2020-03-10 02:48:24,400 epoch 13 - iter 3000/5000 - loss 0.52010982 - samples/sec: 168.50\n",
      "2020-03-10 02:50:01,515 epoch 13 - iter 3500/5000 - loss 0.52038738 - samples/sec: 170.55\n",
      "2020-03-10 02:51:39,201 epoch 13 - iter 4000/5000 - loss 0.52017749 - samples/sec: 169.50\n",
      "2020-03-10 02:53:17,389 epoch 13 - iter 4500/5000 - loss 0.52081899 - samples/sec: 168.43\n",
      "2020-03-10 02:54:55,309 epoch 13 - iter 5000/5000 - loss 0.52133525 - samples/sec: 169.25\n",
      "2020-03-10 02:54:55,378 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 02:54:55,379 EPOCH 13 done: loss 0.5213 - lr 0.1000\n",
      "2020-03-10 02:55:16,510 DEV : loss 0.4702860414981842 - score 0.7752\n",
      "2020-03-10 02:55:21,256 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 02:55:21,258 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 02:56:58,940 epoch 14 - iter 500/5000 - loss 0.50860281 - samples/sec: 170.13\n",
      "2020-03-10 02:58:36,876 epoch 14 - iter 1000/5000 - loss 0.51606838 - samples/sec: 169.25\n",
      "2020-03-10 03:00:14,511 epoch 14 - iter 1500/5000 - loss 0.51656829 - samples/sec: 170.03\n",
      "2020-03-10 03:01:52,394 epoch 14 - iter 2000/5000 - loss 0.51678143 - samples/sec: 169.64\n",
      "2020-03-10 03:03:29,638 epoch 14 - iter 2500/5000 - loss 0.51630849 - samples/sec: 170.21\n",
      "2020-03-10 03:05:07,361 epoch 14 - iter 3000/5000 - loss 0.51739161 - samples/sec: 169.83\n",
      "2020-03-10 03:06:45,842 epoch 14 - iter 3500/5000 - loss 0.51743542 - samples/sec: 168.59\n",
      "2020-03-10 03:08:23,905 epoch 14 - iter 4000/5000 - loss 0.51802660 - samples/sec: 168.73\n",
      "2020-03-10 03:10:02,798 epoch 14 - iter 4500/5000 - loss 0.51819061 - samples/sec: 167.81\n",
      "2020-03-10 03:11:40,868 epoch 14 - iter 5000/5000 - loss 0.51883014 - samples/sec: 169.33\n",
      "2020-03-10 03:11:40,936 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 03:11:40,937 EPOCH 14 done: loss 0.5188 - lr 0.1000\n",
      "2020-03-10 03:11:59,830 DEV : loss 0.4619913697242737 - score 0.7813\n",
      "2020-03-10 03:12:04,550 BAD EPOCHS (no improvement): 2\n",
      "2020-03-10 03:12:04,551 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 03:13:42,219 epoch 15 - iter 500/5000 - loss 0.51946251 - samples/sec: 169.71\n",
      "2020-03-10 03:15:20,063 epoch 15 - iter 1000/5000 - loss 0.51857492 - samples/sec: 169.64\n",
      "2020-03-10 03:16:57,112 epoch 15 - iter 1500/5000 - loss 0.51849562 - samples/sec: 170.51\n",
      "2020-03-10 03:18:35,126 epoch 15 - iter 2000/5000 - loss 0.51807872 - samples/sec: 169.34\n",
      "2020-03-10 03:20:12,863 epoch 15 - iter 2500/5000 - loss 0.51830677 - samples/sec: 169.13\n",
      "2020-03-10 03:21:50,975 epoch 15 - iter 3000/5000 - loss 0.51737234 - samples/sec: 169.56\n",
      "2020-03-10 03:23:28,987 epoch 15 - iter 3500/5000 - loss 0.51726927 - samples/sec: 168.95\n",
      "2020-03-10 03:25:07,329 epoch 15 - iter 4000/5000 - loss 0.51677966 - samples/sec: 167.87\n",
      "2020-03-10 03:26:45,042 epoch 15 - iter 4500/5000 - loss 0.51719361 - samples/sec: 169.49\n",
      "2020-03-10 03:28:23,716 epoch 15 - iter 5000/5000 - loss 0.51735058 - samples/sec: 167.81\n",
      "2020-03-10 03:28:23,782 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 03:28:23,783 EPOCH 15 done: loss 0.5174 - lr 0.1000\n",
      "2020-03-10 03:28:42,842 DEV : loss 0.45646387338638306 - score 0.786\n",
      "2020-03-10 03:28:47,748 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 03:28:50,715 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 03:30:27,562 epoch 16 - iter 500/5000 - loss 0.51529189 - samples/sec: 171.32\n",
      "2020-03-10 03:32:04,981 epoch 16 - iter 1000/5000 - loss 0.51770764 - samples/sec: 170.42\n",
      "2020-03-10 03:33:43,331 epoch 16 - iter 1500/5000 - loss 0.51901309 - samples/sec: 168.80\n",
      "2020-03-10 03:35:21,902 epoch 16 - iter 2000/5000 - loss 0.51902413 - samples/sec: 168.42\n",
      "2020-03-10 03:37:00,128 epoch 16 - iter 2500/5000 - loss 0.51719786 - samples/sec: 169.05\n",
      "2020-03-10 03:38:37,710 epoch 16 - iter 3000/5000 - loss 0.51692700 - samples/sec: 170.21\n",
      "2020-03-10 03:40:15,062 epoch 16 - iter 3500/5000 - loss 0.51642389 - samples/sec: 170.54\n",
      "2020-03-10 03:41:53,857 epoch 16 - iter 4000/5000 - loss 0.51608505 - samples/sec: 167.94\n",
      "2020-03-10 03:43:31,873 epoch 16 - iter 4500/5000 - loss 0.51506218 - samples/sec: 169.35\n",
      "2020-03-10 03:45:08,943 epoch 16 - iter 5000/5000 - loss 0.51618220 - samples/sec: 171.10\n",
      "2020-03-10 03:45:09,010 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 03:45:09,011 EPOCH 16 done: loss 0.5162 - lr 0.1000\n",
      "2020-03-10 03:45:27,867 DEV : loss 0.44731763005256653 - score 0.7932\n",
      "2020-03-10 03:45:32,579 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 03:45:35,572 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 03:47:12,926 epoch 17 - iter 500/5000 - loss 0.51715881 - samples/sec: 170.31\n",
      "2020-03-10 03:48:50,263 epoch 17 - iter 1000/5000 - loss 0.51410909 - samples/sec: 170.23\n",
      "2020-03-10 03:50:27,898 epoch 17 - iter 1500/5000 - loss 0.51342164 - samples/sec: 169.62\n",
      "2020-03-10 03:52:04,914 epoch 17 - iter 2000/5000 - loss 0.51194837 - samples/sec: 171.30\n",
      "2020-03-10 03:53:42,379 epoch 17 - iter 2500/5000 - loss 0.51049205 - samples/sec: 169.94\n",
      "2020-03-10 03:55:20,048 epoch 17 - iter 3000/5000 - loss 0.51041989 - samples/sec: 169.55\n",
      "2020-03-10 03:56:57,258 epoch 17 - iter 3500/5000 - loss 0.51157190 - samples/sec: 170.42\n",
      "2020-03-10 03:58:35,741 epoch 17 - iter 4000/5000 - loss 0.51249141 - samples/sec: 168.19\n",
      "2020-03-10 04:00:12,944 epoch 17 - iter 4500/5000 - loss 0.51241959 - samples/sec: 170.40\n",
      "2020-03-10 04:01:50,120 epoch 17 - iter 5000/5000 - loss 0.51375376 - samples/sec: 170.55\n",
      "2020-03-10 04:01:50,186 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 04:01:50,187 EPOCH 17 done: loss 0.5138 - lr 0.1000\n",
      "2020-03-10 04:02:09,065 DEV : loss 0.44415009021759033 - score 0.7944\n",
      "2020-03-10 04:02:13,776 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 04:02:16,827 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 04:03:53,617 epoch 18 - iter 500/5000 - loss 0.50656784 - samples/sec: 171.38\n",
      "2020-03-10 04:05:30,352 epoch 18 - iter 1000/5000 - loss 0.51188322 - samples/sec: 171.26\n",
      "2020-03-10 04:07:08,071 epoch 18 - iter 1500/5000 - loss 0.51063307 - samples/sec: 169.51\n",
      "2020-03-10 04:08:46,450 epoch 18 - iter 2000/5000 - loss 0.51108448 - samples/sec: 168.35\n",
      "2020-03-10 04:10:23,642 epoch 18 - iter 2500/5000 - loss 0.51077098 - samples/sec: 170.41\n",
      "2020-03-10 04:12:00,893 epoch 18 - iter 3000/5000 - loss 0.51095204 - samples/sec: 170.39\n",
      "2020-03-10 04:13:38,572 epoch 18 - iter 3500/5000 - loss 0.50988128 - samples/sec: 170.16\n",
      "2020-03-10 04:15:16,045 epoch 18 - iter 4000/5000 - loss 0.51036917 - samples/sec: 169.96\n",
      "2020-03-10 04:16:53,283 epoch 18 - iter 4500/5000 - loss 0.51109876 - samples/sec: 170.37\n",
      "2020-03-10 04:18:31,517 epoch 18 - iter 5000/5000 - loss 0.51148961 - samples/sec: 168.55\n",
      "2020-03-10 04:18:31,582 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 04:18:31,583 EPOCH 18 done: loss 0.5115 - lr 0.1000\n",
      "2020-03-10 04:18:50,349 DEV : loss 0.44567620754241943 - score 0.7904\n",
      "2020-03-10 04:18:55,025 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 04:18:55,026 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 04:20:33,053 epoch 19 - iter 500/5000 - loss 0.50985326 - samples/sec: 169.65\n",
      "2020-03-10 04:22:10,287 epoch 19 - iter 1000/5000 - loss 0.51155664 - samples/sec: 170.27\n",
      "2020-03-10 04:23:48,231 epoch 19 - iter 1500/5000 - loss 0.51168574 - samples/sec: 169.67\n",
      "2020-03-10 04:25:26,303 epoch 19 - iter 2000/5000 - loss 0.51043955 - samples/sec: 168.84\n",
      "2020-03-10 04:27:04,659 epoch 19 - iter 2500/5000 - loss 0.50948973 - samples/sec: 169.00\n",
      "2020-03-10 04:28:42,789 epoch 19 - iter 3000/5000 - loss 0.50919973 - samples/sec: 169.27\n",
      "2020-03-10 04:30:19,567 epoch 19 - iter 3500/5000 - loss 0.51010531 - samples/sec: 171.18\n",
      "2020-03-10 04:31:57,007 epoch 19 - iter 4000/5000 - loss 0.51009328 - samples/sec: 170.49\n",
      "2020-03-10 04:33:35,527 epoch 19 - iter 4500/5000 - loss 0.51044521 - samples/sec: 168.50\n",
      "2020-03-10 04:35:13,416 epoch 19 - iter 5000/5000 - loss 0.51012279 - samples/sec: 169.05\n",
      "2020-03-10 04:35:13,481 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 04:35:13,482 EPOCH 19 done: loss 0.5101 - lr 0.1000\n",
      "2020-03-10 04:35:32,754 DEV : loss 0.44923487305641174 - score 0.7876\n",
      "2020-03-10 04:35:37,464 BAD EPOCHS (no improvement): 2\n",
      "2020-03-10 04:35:37,465 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 04:37:15,267 epoch 20 - iter 500/5000 - loss 0.50224934 - samples/sec: 169.68\n",
      "2020-03-10 04:38:53,290 epoch 20 - iter 1000/5000 - loss 0.50589199 - samples/sec: 168.88\n",
      "2020-03-10 04:40:31,312 epoch 20 - iter 1500/5000 - loss 0.50644490 - samples/sec: 168.97\n",
      "2020-03-10 04:42:09,093 epoch 20 - iter 2000/5000 - loss 0.50559794 - samples/sec: 168.89\n",
      "2020-03-10 04:43:46,914 epoch 20 - iter 2500/5000 - loss 0.50598832 - samples/sec: 169.97\n",
      "2020-03-10 04:45:26,006 epoch 20 - iter 3000/5000 - loss 0.50584926 - samples/sec: 167.24\n",
      "2020-03-10 04:47:03,400 epoch 20 - iter 3500/5000 - loss 0.50581735 - samples/sec: 169.77\n",
      "2020-03-10 04:48:41,634 epoch 20 - iter 4000/5000 - loss 0.50692847 - samples/sec: 168.26\n",
      "2020-03-10 04:50:18,762 epoch 20 - iter 4500/5000 - loss 0.50738541 - samples/sec: 170.73\n",
      "2020-03-10 04:51:56,390 epoch 20 - iter 5000/5000 - loss 0.50801204 - samples/sec: 169.29\n",
      "2020-03-10 04:51:56,458 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 04:51:56,459 EPOCH 20 done: loss 0.5080 - lr 0.1000\n",
      "2020-03-10 04:52:15,405 DEV : loss 0.4564714729785919 - score 0.7841\n",
      "2020-03-10 04:52:20,078 BAD EPOCHS (no improvement): 3\n",
      "2020-03-10 04:52:20,080 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 04:53:59,568 epoch 21 - iter 500/5000 - loss 0.49819028 - samples/sec: 167.02\n",
      "2020-03-10 04:55:37,867 epoch 21 - iter 1000/5000 - loss 0.50354582 - samples/sec: 168.41\n",
      "2020-03-10 04:57:15,517 epoch 21 - iter 1500/5000 - loss 0.50645265 - samples/sec: 170.14\n",
      "2020-03-10 04:58:53,535 epoch 21 - iter 2000/5000 - loss 0.50608092 - samples/sec: 168.93\n",
      "2020-03-10 05:00:32,108 epoch 21 - iter 2500/5000 - loss 0.50567797 - samples/sec: 168.48\n",
      "2020-03-10 05:02:09,330 epoch 21 - iter 3000/5000 - loss 0.50547528 - samples/sec: 170.25\n",
      "2020-03-10 05:03:48,141 epoch 21 - iter 3500/5000 - loss 0.50630850 - samples/sec: 167.53\n",
      "2020-03-10 05:05:25,137 epoch 21 - iter 4000/5000 - loss 0.50710073 - samples/sec: 171.34\n",
      "2020-03-10 05:07:03,182 epoch 21 - iter 4500/5000 - loss 0.50670331 - samples/sec: 168.88\n",
      "2020-03-10 05:08:41,070 epoch 21 - iter 5000/5000 - loss 0.50712013 - samples/sec: 169.71\n",
      "2020-03-10 05:08:41,139 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 05:08:41,140 EPOCH 21 done: loss 0.5071 - lr 0.1000\n",
      "2020-03-10 05:09:00,105 DEV : loss 0.43740561604499817 - score 0.7969\n",
      "2020-03-10 05:09:04,808 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 05:09:07,817 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 05:10:45,528 epoch 22 - iter 500/5000 - loss 0.50325612 - samples/sec: 169.73\n",
      "2020-03-10 05:12:22,988 epoch 22 - iter 1000/5000 - loss 0.50429109 - samples/sec: 170.01\n",
      "2020-03-10 05:14:00,934 epoch 22 - iter 1500/5000 - loss 0.50468454 - samples/sec: 168.63\n",
      "2020-03-10 05:15:38,211 epoch 22 - iter 2000/5000 - loss 0.50602670 - samples/sec: 170.26\n",
      "2020-03-10 05:17:14,597 epoch 22 - iter 2500/5000 - loss 0.50531730 - samples/sec: 171.83\n",
      "2020-03-10 05:18:51,512 epoch 22 - iter 3000/5000 - loss 0.50501370 - samples/sec: 170.89\n",
      "2020-03-10 05:20:29,152 epoch 22 - iter 3500/5000 - loss 0.50475012 - samples/sec: 169.64\n",
      "2020-03-10 05:22:07,588 epoch 22 - iter 4000/5000 - loss 0.50528737 - samples/sec: 168.17\n",
      "2020-03-10 05:23:44,736 epoch 22 - iter 4500/5000 - loss 0.50592326 - samples/sec: 170.50\n",
      "2020-03-10 05:25:22,407 epoch 22 - iter 5000/5000 - loss 0.50584653 - samples/sec: 169.62\n",
      "2020-03-10 05:25:22,475 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 05:25:22,476 EPOCH 22 done: loss 0.5058 - lr 0.1000\n",
      "2020-03-10 05:25:41,725 DEV : loss 0.4420560598373413 - score 0.7935\n",
      "2020-03-10 05:25:46,457 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 05:25:46,458 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 05:27:23,605 epoch 23 - iter 500/5000 - loss 0.50603687 - samples/sec: 170.84\n",
      "2020-03-10 05:29:01,615 epoch 23 - iter 1000/5000 - loss 0.50527118 - samples/sec: 168.99\n",
      "2020-03-10 05:30:40,318 epoch 23 - iter 1500/5000 - loss 0.50542876 - samples/sec: 167.74\n",
      "2020-03-10 05:32:17,663 epoch 23 - iter 2000/5000 - loss 0.50443123 - samples/sec: 169.71\n",
      "2020-03-10 05:33:54,381 epoch 23 - iter 2500/5000 - loss 0.50490003 - samples/sec: 171.30\n",
      "2020-03-10 05:35:32,508 epoch 23 - iter 3000/5000 - loss 0.50409575 - samples/sec: 169.22\n",
      "2020-03-10 05:37:11,264 epoch 23 - iter 3500/5000 - loss 0.50347340 - samples/sec: 167.62\n",
      "2020-03-10 05:38:48,401 epoch 23 - iter 4000/5000 - loss 0.50313562 - samples/sec: 171.05\n",
      "2020-03-10 05:40:26,280 epoch 23 - iter 4500/5000 - loss 0.50285875 - samples/sec: 169.21\n",
      "2020-03-10 05:42:04,562 epoch 23 - iter 5000/5000 - loss 0.50355098 - samples/sec: 168.48\n",
      "2020-03-10 05:42:04,629 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 05:42:04,630 EPOCH 23 done: loss 0.5036 - lr 0.1000\n",
      "2020-03-10 05:42:23,726 DEV : loss 0.43721798062324524 - score 0.7987\n",
      "2020-03-10 05:42:28,448 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 05:42:31,410 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 05:44:09,371 epoch 24 - iter 500/5000 - loss 0.49470752 - samples/sec: 169.34\n",
      "2020-03-10 05:45:46,416 epoch 24 - iter 1000/5000 - loss 0.50083678 - samples/sec: 170.64\n",
      "2020-03-10 05:47:23,808 epoch 24 - iter 1500/5000 - loss 0.49937005 - samples/sec: 169.99\n",
      "2020-03-10 05:49:01,609 epoch 24 - iter 2000/5000 - loss 0.50041816 - samples/sec: 169.85\n",
      "2020-03-10 05:50:40,949 epoch 24 - iter 2500/5000 - loss 0.50091975 - samples/sec: 166.64\n",
      "2020-03-10 05:52:19,079 epoch 24 - iter 3000/5000 - loss 0.50083881 - samples/sec: 168.92\n",
      "2020-03-10 05:53:56,937 epoch 24 - iter 3500/5000 - loss 0.50127216 - samples/sec: 169.33\n",
      "2020-03-10 05:55:35,936 epoch 24 - iter 4000/5000 - loss 0.50210350 - samples/sec: 167.35\n",
      "2020-03-10 05:57:13,720 epoch 24 - iter 4500/5000 - loss 0.50278687 - samples/sec: 169.47\n",
      "2020-03-10 05:58:50,720 epoch 24 - iter 5000/5000 - loss 0.50285046 - samples/sec: 170.89\n",
      "2020-03-10 05:58:50,786 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 05:58:50,787 EPOCH 24 done: loss 0.5029 - lr 0.1000\n",
      "2020-03-10 05:59:09,437 DEV : loss 0.44549161195755005 - score 0.7938\n",
      "2020-03-10 05:59:14,426 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 05:59:14,428 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 06:00:51,852 epoch 25 - iter 500/5000 - loss 0.50466748 - samples/sec: 169.88\n",
      "2020-03-10 06:02:29,371 epoch 25 - iter 1000/5000 - loss 0.50188662 - samples/sec: 169.95\n",
      "2020-03-10 06:04:06,385 epoch 25 - iter 1500/5000 - loss 0.50170865 - samples/sec: 170.81\n",
      "2020-03-10 06:05:44,153 epoch 25 - iter 2000/5000 - loss 0.50006445 - samples/sec: 169.42\n",
      "2020-03-10 06:07:22,060 epoch 25 - iter 2500/5000 - loss 0.50186837 - samples/sec: 169.62\n",
      "2020-03-10 06:09:00,869 epoch 25 - iter 3000/5000 - loss 0.50055609 - samples/sec: 167.56\n",
      "2020-03-10 06:10:39,627 epoch 25 - iter 3500/5000 - loss 0.50127386 - samples/sec: 167.76\n",
      "2020-03-10 06:12:17,428 epoch 25 - iter 4000/5000 - loss 0.50137772 - samples/sec: 169.34\n",
      "2020-03-10 06:13:55,183 epoch 25 - iter 4500/5000 - loss 0.50161002 - samples/sec: 169.40\n",
      "2020-03-10 06:15:32,751 epoch 25 - iter 5000/5000 - loss 0.50156139 - samples/sec: 170.24\n",
      "2020-03-10 06:15:32,818 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 06:15:32,819 EPOCH 25 done: loss 0.5016 - lr 0.1000\n",
      "2020-03-10 06:15:51,376 DEV : loss 0.43480128049850464 - score 0.8001\n",
      "2020-03-10 06:15:56,366 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 06:15:59,370 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 06:17:36,486 epoch 26 - iter 500/5000 - loss 0.50454701 - samples/sec: 170.77\n",
      "2020-03-10 06:19:13,961 epoch 26 - iter 1000/5000 - loss 0.50096611 - samples/sec: 169.76\n",
      "2020-03-10 06:20:51,375 epoch 26 - iter 1500/5000 - loss 0.49868123 - samples/sec: 170.54\n",
      "2020-03-10 06:22:29,477 epoch 26 - iter 2000/5000 - loss 0.49969914 - samples/sec: 168.79\n",
      "2020-03-10 06:24:07,534 epoch 26 - iter 2500/5000 - loss 0.49956354 - samples/sec: 169.38\n",
      "2020-03-10 06:25:44,470 epoch 26 - iter 3000/5000 - loss 0.50052062 - samples/sec: 170.85\n",
      "2020-03-10 06:27:22,466 epoch 26 - iter 3500/5000 - loss 0.50091267 - samples/sec: 169.49\n",
      "2020-03-10 06:29:00,309 epoch 26 - iter 4000/5000 - loss 0.49974737 - samples/sec: 169.19\n",
      "2020-03-10 06:30:39,070 epoch 26 - iter 4500/5000 - loss 0.50003070 - samples/sec: 168.09\n",
      "2020-03-10 06:32:17,324 epoch 26 - iter 5000/5000 - loss 0.50029225 - samples/sec: 168.45\n",
      "2020-03-10 06:32:17,394 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 06:32:17,395 EPOCH 26 done: loss 0.5003 - lr 0.1000\n",
      "2020-03-10 06:32:36,582 DEV : loss 0.4337315559387207 - score 0.7976\n",
      "2020-03-10 06:32:41,280 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 06:32:41,282 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 06:34:18,754 epoch 27 - iter 500/5000 - loss 0.49769602 - samples/sec: 170.67\n",
      "2020-03-10 06:35:57,196 epoch 27 - iter 1000/5000 - loss 0.49729638 - samples/sec: 168.10\n",
      "2020-03-10 06:37:34,821 epoch 27 - iter 1500/5000 - loss 0.49877086 - samples/sec: 169.58\n",
      "2020-03-10 06:39:12,366 epoch 27 - iter 2000/5000 - loss 0.49952878 - samples/sec: 170.30\n",
      "2020-03-10 06:40:50,218 epoch 27 - iter 2500/5000 - loss 0.49931143 - samples/sec: 169.07\n",
      "2020-03-10 06:42:28,880 epoch 27 - iter 3000/5000 - loss 0.49803411 - samples/sec: 168.27\n",
      "2020-03-10 06:44:05,923 epoch 27 - iter 3500/5000 - loss 0.49847770 - samples/sec: 170.62\n",
      "2020-03-10 06:45:43,067 epoch 27 - iter 4000/5000 - loss 0.49904196 - samples/sec: 171.04\n",
      "2020-03-10 06:47:20,478 epoch 27 - iter 4500/5000 - loss 0.49931465 - samples/sec: 170.00\n",
      "2020-03-10 06:48:58,349 epoch 27 - iter 5000/5000 - loss 0.49889018 - samples/sec: 169.72\n",
      "2020-03-10 06:48:58,415 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 06:48:58,416 EPOCH 27 done: loss 0.4989 - lr 0.1000\n",
      "2020-03-10 06:49:17,249 DEV : loss 0.43314361572265625 - score 0.8007\n",
      "2020-03-10 06:49:21,969 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 06:49:25,009 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 06:51:02,830 epoch 28 - iter 500/5000 - loss 0.50252200 - samples/sec: 169.57\n",
      "2020-03-10 06:52:40,517 epoch 28 - iter 1000/5000 - loss 0.49904462 - samples/sec: 169.53\n",
      "2020-03-10 06:54:18,955 epoch 28 - iter 1500/5000 - loss 0.49966693 - samples/sec: 168.13\n",
      "2020-03-10 06:55:56,788 epoch 28 - iter 2000/5000 - loss 0.50012156 - samples/sec: 169.27\n",
      "2020-03-10 06:57:34,774 epoch 28 - iter 2500/5000 - loss 0.49874913 - samples/sec: 169.56\n",
      "2020-03-10 06:59:12,503 epoch 28 - iter 3000/5000 - loss 0.49876070 - samples/sec: 169.40\n",
      "2020-03-10 07:00:50,141 epoch 28 - iter 3500/5000 - loss 0.49812582 - samples/sec: 169.68\n",
      "2020-03-10 07:02:27,719 epoch 28 - iter 4000/5000 - loss 0.49740618 - samples/sec: 169.75\n",
      "2020-03-10 07:04:04,839 epoch 28 - iter 4500/5000 - loss 0.49780364 - samples/sec: 170.51\n",
      "2020-03-10 07:05:41,697 epoch 28 - iter 5000/5000 - loss 0.49815031 - samples/sec: 171.00\n",
      "2020-03-10 07:05:41,765 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 07:05:41,766 EPOCH 28 done: loss 0.4982 - lr 0.1000\n",
      "2020-03-10 07:06:01,214 DEV : loss 0.43381553888320923 - score 0.8013\n",
      "2020-03-10 07:06:05,892 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 07:06:08,849 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 07:07:46,996 epoch 29 - iter 500/5000 - loss 0.50158751 - samples/sec: 168.98\n",
      "2020-03-10 07:09:24,760 epoch 29 - iter 1000/5000 - loss 0.49630972 - samples/sec: 169.36\n",
      "2020-03-10 07:11:01,794 epoch 29 - iter 1500/5000 - loss 0.49631561 - samples/sec: 171.27\n",
      "2020-03-10 07:12:38,979 epoch 29 - iter 2000/5000 - loss 0.49572007 - samples/sec: 170.48\n",
      "2020-03-10 07:14:15,920 epoch 29 - iter 2500/5000 - loss 0.49527171 - samples/sec: 170.88\n",
      "2020-03-10 07:15:54,107 epoch 29 - iter 3000/5000 - loss 0.49566737 - samples/sec: 168.99\n",
      "2020-03-10 07:17:32,911 epoch 29 - iter 3500/5000 - loss 0.49597521 - samples/sec: 168.09\n",
      "2020-03-10 07:19:10,923 epoch 29 - iter 4000/5000 - loss 0.49632208 - samples/sec: 169.00\n",
      "2020-03-10 07:20:48,657 epoch 29 - iter 4500/5000 - loss 0.49756854 - samples/sec: 169.46\n",
      "2020-03-10 07:22:26,986 epoch 29 - iter 5000/5000 - loss 0.49737695 - samples/sec: 168.92\n",
      "2020-03-10 07:22:27,050 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 07:22:27,051 EPOCH 29 done: loss 0.4974 - lr 0.1000\n",
      "2020-03-10 07:22:45,957 DEV : loss 0.43222689628601074 - score 0.7995\n",
      "2020-03-10 07:22:50,643 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 07:22:50,645 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 07:24:28,404 epoch 30 - iter 500/5000 - loss 0.48753213 - samples/sec: 170.75\n",
      "2020-03-10 07:26:06,047 epoch 30 - iter 1000/5000 - loss 0.49021252 - samples/sec: 169.64\n",
      "2020-03-10 07:27:44,247 epoch 30 - iter 1500/5000 - loss 0.49237513 - samples/sec: 169.17\n",
      "2020-03-10 07:29:22,270 epoch 30 - iter 2000/5000 - loss 0.49577487 - samples/sec: 168.90\n",
      "2020-03-10 07:31:00,524 epoch 30 - iter 2500/5000 - loss 0.49646207 - samples/sec: 169.07\n",
      "2020-03-10 07:32:37,212 epoch 30 - iter 3000/5000 - loss 0.49722844 - samples/sec: 171.40\n",
      "2020-03-10 07:34:14,923 epoch 30 - iter 3500/5000 - loss 0.49675742 - samples/sec: 169.50\n",
      "2020-03-10 07:35:53,789 epoch 30 - iter 4000/5000 - loss 0.49649192 - samples/sec: 167.98\n",
      "2020-03-10 07:37:31,820 epoch 30 - iter 4500/5000 - loss 0.49646459 - samples/sec: 168.86\n",
      "2020-03-10 07:39:09,488 epoch 30 - iter 5000/5000 - loss 0.49609332 - samples/sec: 170.16\n",
      "2020-03-10 07:39:09,556 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 07:39:09,557 EPOCH 30 done: loss 0.4961 - lr 0.1000\n",
      "2020-03-10 07:39:28,498 DEV : loss 0.4338056147098541 - score 0.7993\n",
      "2020-03-10 07:39:33,225 BAD EPOCHS (no improvement): 2\n",
      "2020-03-10 07:39:33,227 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 07:41:10,809 epoch 31 - iter 500/5000 - loss 0.49158362 - samples/sec: 169.87\n",
      "2020-03-10 07:42:47,689 epoch 31 - iter 1000/5000 - loss 0.48911290 - samples/sec: 171.53\n",
      "2020-03-10 07:44:24,602 epoch 31 - iter 1500/5000 - loss 0.49103032 - samples/sec: 171.07\n",
      "2020-03-10 07:46:03,239 epoch 31 - iter 2000/5000 - loss 0.49251417 - samples/sec: 167.86\n",
      "2020-03-10 07:47:41,016 epoch 31 - iter 2500/5000 - loss 0.49368018 - samples/sec: 169.35\n",
      "2020-03-10 07:49:18,239 epoch 31 - iter 3000/5000 - loss 0.49363024 - samples/sec: 170.97\n",
      "2020-03-10 07:50:56,602 epoch 31 - iter 3500/5000 - loss 0.49365085 - samples/sec: 168.32\n",
      "2020-03-10 07:52:33,348 epoch 31 - iter 4000/5000 - loss 0.49441353 - samples/sec: 171.33\n",
      "2020-03-10 07:54:11,255 epoch 31 - iter 4500/5000 - loss 0.49441457 - samples/sec: 169.18\n",
      "2020-03-10 07:55:49,308 epoch 31 - iter 5000/5000 - loss 0.49461026 - samples/sec: 168.89\n",
      "2020-03-10 07:55:49,375 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 07:55:49,376 EPOCH 31 done: loss 0.4946 - lr 0.1000\n",
      "2020-03-10 07:56:08,361 DEV : loss 0.4507254362106323 - score 0.7884\n",
      "2020-03-10 07:56:13,082 BAD EPOCHS (no improvement): 3\n",
      "2020-03-10 07:56:13,084 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 07:57:50,281 epoch 32 - iter 500/5000 - loss 0.49195377 - samples/sec: 170.77\n",
      "2020-03-10 07:59:28,250 epoch 32 - iter 1000/5000 - loss 0.49495356 - samples/sec: 168.76\n",
      "2020-03-10 08:01:06,057 epoch 32 - iter 1500/5000 - loss 0.49298856 - samples/sec: 169.48\n",
      "2020-03-10 08:02:43,727 epoch 32 - iter 2000/5000 - loss 0.49280942 - samples/sec: 169.70\n",
      "2020-03-10 08:04:21,533 epoch 32 - iter 2500/5000 - loss 0.49343799 - samples/sec: 168.96\n",
      "2020-03-10 08:05:59,313 epoch 32 - iter 3000/5000 - loss 0.49283481 - samples/sec: 169.56\n",
      "2020-03-10 08:07:37,017 epoch 32 - iter 3500/5000 - loss 0.49286879 - samples/sec: 169.71\n",
      "2020-03-10 08:09:15,482 epoch 32 - iter 4000/5000 - loss 0.49383549 - samples/sec: 167.81\n",
      "2020-03-10 08:10:53,796 epoch 32 - iter 4500/5000 - loss 0.49420644 - samples/sec: 168.67\n",
      "2020-03-10 08:12:32,316 epoch 32 - iter 5000/5000 - loss 0.49446169 - samples/sec: 168.26\n",
      "2020-03-10 08:12:32,393 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 08:12:32,394 EPOCH 32 done: loss 0.4945 - lr 0.1000\n",
      "2020-03-10 08:12:51,180 DEV : loss 0.44352105259895325 - score 0.7937\n",
      "2020-03-10 08:12:55,923 BAD EPOCHS (no improvement): 4\n",
      "2020-03-10 08:12:55,925 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 08:14:35,324 epoch 33 - iter 500/5000 - loss 0.49064165 - samples/sec: 167.38\n",
      "2020-03-10 08:16:12,427 epoch 33 - iter 1000/5000 - loss 0.48845376 - samples/sec: 170.62\n",
      "2020-03-10 08:17:49,534 epoch 33 - iter 1500/5000 - loss 0.48862259 - samples/sec: 170.55\n",
      "2020-03-10 08:19:26,910 epoch 33 - iter 2000/5000 - loss 0.48991489 - samples/sec: 170.05\n",
      "2020-03-10 08:21:04,162 epoch 33 - iter 2500/5000 - loss 0.49165391 - samples/sec: 170.33\n",
      "2020-03-10 08:22:42,104 epoch 33 - iter 3000/5000 - loss 0.49248617 - samples/sec: 169.07\n",
      "2020-03-10 08:24:19,975 epoch 33 - iter 3500/5000 - loss 0.49219814 - samples/sec: 169.75\n",
      "2020-03-10 08:25:57,249 epoch 33 - iter 4000/5000 - loss 0.49236803 - samples/sec: 170.18\n",
      "2020-03-10 08:27:36,340 epoch 33 - iter 4500/5000 - loss 0.49241634 - samples/sec: 167.03\n",
      "2020-03-10 08:29:14,063 epoch 33 - iter 5000/5000 - loss 0.49272470 - samples/sec: 169.50\n",
      "2020-03-10 08:29:14,133 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 08:29:14,134 EPOCH 33 done: loss 0.4927 - lr 0.1000\n",
      "2020-03-10 08:29:35,342 DEV : loss 0.4326549172401428 - score 0.8026\n",
      "2020-03-10 08:29:40,014 BAD EPOCHS (no improvement): 0\n",
      "2020-03-10 08:29:42,974 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 08:31:20,893 epoch 34 - iter 500/5000 - loss 0.49333090 - samples/sec: 169.53\n",
      "2020-03-10 08:32:57,987 epoch 34 - iter 1000/5000 - loss 0.49236891 - samples/sec: 170.69\n",
      "2020-03-10 08:34:36,613 epoch 34 - iter 1500/5000 - loss 0.49158647 - samples/sec: 168.00\n",
      "2020-03-10 08:36:14,623 epoch 34 - iter 2000/5000 - loss 0.49161080 - samples/sec: 169.00\n",
      "2020-03-10 08:37:53,506 epoch 34 - iter 2500/5000 - loss 0.49205932 - samples/sec: 167.75\n",
      "2020-03-10 08:39:31,214 epoch 34 - iter 3000/5000 - loss 0.49140957 - samples/sec: 169.68\n",
      "2020-03-10 08:41:08,246 epoch 34 - iter 3500/5000 - loss 0.49165074 - samples/sec: 170.89\n",
      "2020-03-10 08:42:46,580 epoch 34 - iter 4000/5000 - loss 0.49208524 - samples/sec: 167.95\n",
      "2020-03-10 08:44:24,435 epoch 34 - iter 4500/5000 - loss 0.49170841 - samples/sec: 169.37\n",
      "2020-03-10 08:46:02,622 epoch 34 - iter 5000/5000 - loss 0.49266228 - samples/sec: 168.74\n",
      "2020-03-10 08:46:02,688 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 08:46:02,690 EPOCH 34 done: loss 0.4927 - lr 0.1000\n",
      "2020-03-10 08:46:21,573 DEV : loss 0.4646569788455963 - score 0.7843\n",
      "2020-03-10 08:46:26,258 BAD EPOCHS (no improvement): 1\n",
      "2020-03-10 08:46:26,260 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 08:48:04,507 epoch 35 - iter 500/5000 - loss 0.49211700 - samples/sec: 169.31\n",
      "2020-03-10 08:49:42,928 epoch 35 - iter 1000/5000 - loss 0.48960101 - samples/sec: 168.20\n",
      "2020-03-10 08:51:21,797 epoch 35 - iter 1500/5000 - loss 0.49050044 - samples/sec: 167.45\n",
      "2020-03-10 08:52:59,872 epoch 35 - iter 2000/5000 - loss 0.49111793 - samples/sec: 168.91\n",
      "2020-03-10 08:54:37,544 epoch 35 - iter 2500/5000 - loss 0.49184583 - samples/sec: 169.61\n",
      "2020-03-10 08:56:14,855 epoch 35 - iter 3000/5000 - loss 0.49038704 - samples/sec: 170.23\n",
      "2020-03-10 08:57:51,926 epoch 35 - iter 3500/5000 - loss 0.48923418 - samples/sec: 170.75\n",
      "2020-03-10 08:59:29,718 epoch 35 - iter 4000/5000 - loss 0.48993737 - samples/sec: 169.38\n",
      "2020-03-10 09:01:07,934 epoch 35 - iter 4500/5000 - loss 0.49013324 - samples/sec: 168.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-417:\n",
      "Process Process-419:\n",
      "Process Process-418:\n",
      "Process Process-420:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-10 09:04:44,841 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-422:\n",
      "Process Process-421:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-10 09:04:44,844 Exiting from training early.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-10 09:04:44,847 Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1367b7dd0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-10 09:04:48,074 Done.\n",
      "2020-03-10 09:04:48,075 ----------------------------------------------------------------------------------------------------\n",
      "2020-03-10 09:04:48,076 Testing using best model ...\n",
      "2020-03-10 09:04:48,078 loading file model-saves/best-model.pt\n",
      "2020-03-10 09:05:06,877 0.794\t0.794\t0.794\n",
      "2020-03-10 09:05:06,880 \n",
      "MICRO_AVG: acc 0.6584 - f1-score 0.794\n",
      "MACRO_AVG: acc 0.6583 - f1-score 0.794\n",
      "0          tp: 7925 - fp: 1917 - fn: 2203 - tn: 7955 - precision: 0.8052 - recall: 0.7825 - accuracy: 0.6579 - f1-score: 0.7937\n",
      "4          tp: 7955 - fp: 2203 - fn: 1917 - tn: 7925 - precision: 0.7831 - recall: 0.8058 - accuracy: 0.6588 - f1-score: 0.7943\n",
      "2020-03-10 09:05:06,881 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.794,\n",
       " 'dev_score_history': [0.7317,\n",
       "  0.7446,\n",
       "  0.7539,\n",
       "  0.7652,\n",
       "  0.7648,\n",
       "  0.7749,\n",
       "  0.777,\n",
       "  0.7739,\n",
       "  0.7775,\n",
       "  0.7819,\n",
       "  0.7798,\n",
       "  0.7847,\n",
       "  0.7752,\n",
       "  0.7813,\n",
       "  0.786,\n",
       "  0.7932,\n",
       "  0.7944,\n",
       "  0.7904,\n",
       "  0.7876,\n",
       "  0.7841,\n",
       "  0.7969,\n",
       "  0.7935,\n",
       "  0.7987,\n",
       "  0.7938,\n",
       "  0.8001,\n",
       "  0.7976,\n",
       "  0.8007,\n",
       "  0.8013,\n",
       "  0.7995,\n",
       "  0.7993,\n",
       "  0.7884,\n",
       "  0.7937,\n",
       "  0.8026,\n",
       "  0.7843],\n",
       " 'train_loss_history': [0.6266119081437588,\n",
       "  0.5836598127663135,\n",
       "  0.568054846316576,\n",
       "  0.5564922459721565,\n",
       "  0.5492649371296168,\n",
       "  0.5437442660212517,\n",
       "  0.5397270953536034,\n",
       "  0.5343264965295792,\n",
       "  0.5314284939736128,\n",
       "  0.5289126058280468,\n",
       "  0.5255283281028271,\n",
       "  0.5234941969186068,\n",
       "  0.5213352509021759,\n",
       "  0.5188301391690969,\n",
       "  0.5173505823075771,\n",
       "  0.5161822039544582,\n",
       "  0.5137537573516369,\n",
       "  0.5114896131515503,\n",
       "  0.510122787898779,\n",
       "  0.5080120367825032,\n",
       "  0.5071201262533664,\n",
       "  0.5058465283244848,\n",
       "  0.5035509783357381,\n",
       "  0.5028504619300366,\n",
       "  0.5015613921701908,\n",
       "  0.5002922531247139,\n",
       "  0.4988901760816574,\n",
       "  0.498150307944417,\n",
       "  0.49737695242762564,\n",
       "  0.4960933158189058,\n",
       "  0.4946102640479803,\n",
       "  0.4944616883635521,\n",
       "  0.49272469676434993,\n",
       "  0.49266228331923484],\n",
       " 'dev_loss_history': [tensor(0.5377),\n",
       "  tensor(0.5238),\n",
       "  tensor(0.5033),\n",
       "  tensor(0.4925),\n",
       "  tensor(0.4904),\n",
       "  tensor(0.4780),\n",
       "  tensor(0.4737),\n",
       "  tensor(0.4702),\n",
       "  tensor(0.4689),\n",
       "  tensor(0.4652),\n",
       "  tensor(0.4640),\n",
       "  tensor(0.4588),\n",
       "  tensor(0.4703),\n",
       "  tensor(0.4620),\n",
       "  tensor(0.4565),\n",
       "  tensor(0.4473),\n",
       "  tensor(0.4442),\n",
       "  tensor(0.4457),\n",
       "  tensor(0.4492),\n",
       "  tensor(0.4565),\n",
       "  tensor(0.4374),\n",
       "  tensor(0.4421),\n",
       "  tensor(0.4372),\n",
       "  tensor(0.4455),\n",
       "  tensor(0.4348),\n",
       "  tensor(0.4337),\n",
       "  tensor(0.4331),\n",
       "  tensor(0.4338),\n",
       "  tensor(0.4322),\n",
       "  tensor(0.4338),\n",
       "  tensor(0.4507),\n",
       "  tensor(0.4435),\n",
       "  tensor(0.4327),\n",
       "  tensor(0.4647)]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train('model-saves',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=8,\n",
    "              max_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-10 09:38:22,686 loading file model-saves/final-model.pt\n",
      "[4 (0.9295905232429504)] \n",
      " [0 (0.9557440876960754)]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "classifier = TextClassifier.load('model-saves/final-model.pt')\n",
    "\n",
    "pos_sentence = Sentence(preprocess('I love Python!'))\n",
    "neg_sentence = Sentence(preprocess('Python is the worst!'))\n",
    "\n",
    "classifier.predict(pos_sentence)\n",
    "classifier.predict(neg_sentence)\n",
    "\n",
    "print(pos_sentence.labels, \"\\n\", neg_sentence.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
